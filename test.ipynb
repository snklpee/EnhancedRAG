{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790fc5b8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e277896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.loader import DocumentLoader\n",
    "from src.ingestion.chunker import DocumentChunker\n",
    "from src.ingestion.HuggingFaceEmbedder import HuggingFaceEmbedder\n",
    "from config.settings import settings\n",
    "from src.ingestion.VectorStoreManager import VectorStoreManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03cd1b",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d929d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DocumentLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6e2ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] list_filenames: time=0.00s, count=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graph_Databases_for_Beginners.pdf',\n",
       " 'Project_4_Sankalp_Mane.pdf',\n",
       " 'requirements.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = loader.list_filenames(\"pdfs\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc70f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] load_documents: time=1.33s, count=70\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load_documents(\"pdfs\",file_names=files)\n",
    "# print(type(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab29a38c",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a577bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "chunker = DocumentChunker(\n",
    "    hf_embedding_model=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88279a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] chunk_documents: time=0.12s, count=122\n",
      "[METRICS] get_docs_token_count: time=0.05s, count=122\n"
     ]
    }
   ],
   "source": [
    "chunks = chunker.chunk_documents(docs)\n",
    "token_count = chunker.get_docs_token_count(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a9a4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "33989\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538524c",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c0268db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "embedder = HuggingFaceEmbedder(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "060fd8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.05s, count=32\n",
      "dimension 768\n"
     ]
    }
   ],
   "source": [
    "v1  = embedder.embed_query(chunks[0].page_content)\n",
    "print(\"dimension\",len(v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db6a20",
   "metadata": {},
   "source": [
    "### Vector Store Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ace27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VectorStoreManager(embedding_function=embedder,index_name=\"pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ce72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Created in‚Äêmemory FAISS index 'pdfs' (dim=768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.10s, count=4\n"
     ]
    }
   ],
   "source": [
    "vs.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd1b5100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Added 122 docs into 'pdfs'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_documents: time=45.21s, count=33989\n",
      "[METRICS] add_documents: time=45.27s, count=122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['7211ebd7-9c3b-4bf4-9ca4-447db1af927e',\n",
       " '047b2ba5-1739-47eb-a3eb-ef54c08f4a65',\n",
       " 'b595bb2d-1dfc-4410-af7b-9494c4b2b027',\n",
       " '07f8620a-65de-47dc-a0fb-1f416f22e4c7',\n",
       " '93aa3838-4e9b-4084-85a9-6985e02d5b18',\n",
       " '89b0371c-637c-4f8b-9a7d-80183695d13e',\n",
       " 'e38f711e-1dc7-43ae-b068-289717d5f116',\n",
       " '9c44a0ab-6e2a-4618-9a8a-49183c9d51d5',\n",
       " '7951c775-d05b-492e-b7d9-6fe2a13469e5',\n",
       " 'c04cd936-466c-4c8d-988c-fcb8bfc286f7',\n",
       " '62bd2e04-2a0d-48cd-89a2-577e87e96d18',\n",
       " 'd433fc4f-aa36-4981-a85f-7a5bd6e3dd1a',\n",
       " '49955d8e-007f-405a-a90c-2283e4cb2162',\n",
       " '959628c0-0cc9-46a6-a848-6309323908d5',\n",
       " '84dec566-5f0f-48fc-a030-3568b26d3ea8',\n",
       " '8ed45d79-f502-4bbc-b858-8dac9439f69a',\n",
       " 'd5130b79-c44b-45e9-a6e8-ed7e18f95921',\n",
       " 'bbcb7b70-86bf-4b88-ac97-4b2e1184391f',\n",
       " '8efae152-e7dc-41b4-8c9b-ef69b730509e',\n",
       " '492fd4fd-dc81-47a0-a41f-cab3045f233b',\n",
       " '27d66687-5bfa-4066-ad81-247052f59954',\n",
       " 'dbee5495-6025-4134-aebc-44f39ac314ef',\n",
       " 'fdff51cb-47ca-4b4e-8dfa-a2cc11f1701d',\n",
       " '3b51237a-877c-4418-bd9c-005d8f230a6f',\n",
       " '4cb26c9a-c933-4f8d-a7ce-cdb720b11718',\n",
       " 'a337c71d-e3c9-48f7-bb40-ffba88621634',\n",
       " '1f2a631c-7446-42bb-b9eb-5570d779ad92',\n",
       " '46046ee6-45ba-4293-9845-8b6a0a6198ba',\n",
       " '744dbf0e-209f-4b48-a106-d4ae1aa68063',\n",
       " '4220ece8-5930-4cae-aaf7-92ac0abe07a2',\n",
       " '3c629cf8-5e34-40ef-a27b-41da17a1637c',\n",
       " 'b99b83d1-61a1-4462-a646-0fe0604c0667',\n",
       " 'a71a17d4-6ba7-497a-bf9a-86dc9aa3ea9b',\n",
       " '52d1dbd2-f00c-4763-9b6c-5019134f8b5c',\n",
       " '525cd4e8-f6ba-4322-89c9-7de03051821a',\n",
       " 'b1e63e40-6dd6-48cf-ae0f-0d14fd957cac',\n",
       " '3b97ca16-eebb-44b0-ae76-639802a1fd19',\n",
       " '43d0ee62-a502-495a-91cc-1d2be6f7644a',\n",
       " '87544a10-44d0-4e8c-b585-2a3a5b6b6a91',\n",
       " '7fcce47e-e8d5-4c02-9a3a-e0246eee9721',\n",
       " '8a2de9da-536e-4f38-8dc7-cbe86b263aeb',\n",
       " 'fa2b2fcf-d0d3-4394-8c2a-bf6864f45e2f',\n",
       " '810d0d53-977b-40f4-bfb7-dc61bc529411',\n",
       " 'c0a5f323-9338-40b8-a166-97de185ae291',\n",
       " '094658bb-ab7d-4b74-8187-c15d4f2a08f3',\n",
       " 'f0617e4d-335e-4c89-ac33-5b2f450e8c8c',\n",
       " '019605fc-5cc0-45f4-a3b1-d5ae1451ab64',\n",
       " '4199594e-371f-41b1-b036-4a4f2d6f9876',\n",
       " '65a5ece6-62a0-49b1-938d-ce08962d1712',\n",
       " 'da5c19ac-9fef-4e04-a18c-c2bc17cc34ce',\n",
       " '947e9814-91c3-4e19-b82b-0ecf12aa2568',\n",
       " 'b9041e69-1db4-4a17-9a71-5468888540e7',\n",
       " '370ec42f-162b-43d2-ad72-f5aa681f00e5',\n",
       " 'ef752a47-6353-47e5-8826-f177ac97d9a2',\n",
       " '4c7d66cc-5fa0-41e3-8971-4ccbc3602df9',\n",
       " '85abff5b-7378-4a79-aef1-e84eeefe6c31',\n",
       " '311cfcbf-bd23-4669-b20a-f41134a3eadf',\n",
       " '67f9c2f1-d353-45b5-a7d6-ac959afeb76f',\n",
       " '74113b9c-b0c8-494a-8008-067c5cdfc717',\n",
       " '38a60033-db99-4eb7-a856-fa9a8fc0bb20',\n",
       " 'fc5fa978-6fe2-4a84-a524-a6ad20aae888',\n",
       " '797322d6-1cc8-4647-8c0f-c8940e07dc35',\n",
       " 'c98db823-be1e-4553-b226-4adac56e0dda',\n",
       " '1bdc11d1-83dd-4b2d-95c1-4a1dabe4cb48',\n",
       " '65497b22-06bf-42d4-8740-160b265bc609',\n",
       " 'de97438e-d60c-429f-9517-76e2b706c701',\n",
       " '8c5e5b50-aa69-4b63-a84e-e8a5a592a778',\n",
       " 'f48713ff-393b-481c-be81-aa3c45b468c9',\n",
       " '05076049-cbbd-4d6f-963b-6314835a10f5',\n",
       " '6266a39d-fd97-4f1d-a1ba-5414867a99fd',\n",
       " '2503be08-e7b3-4407-9858-238f1e9807fc',\n",
       " '8c476194-877a-485f-a0b6-ee22cb854435',\n",
       " 'd50f1760-ea8e-4407-bd77-dfdca8f093ac',\n",
       " '45619f08-8faf-4a03-b9bc-274845a87498',\n",
       " 'ffb85df5-b949-476d-bb02-6423b4248020',\n",
       " 'cc474c4b-fe67-433d-a414-f383bcf89452',\n",
       " '9dbf9beb-40c6-462a-aac9-edee9985d121',\n",
       " 'd5124b63-c9a7-4606-8e1e-4f57ecec89a8',\n",
       " '1d67b043-439c-4836-be64-88e9254f8f7d',\n",
       " 'b0fc54b9-bde0-408d-8c80-bbf0bbbca066',\n",
       " '9535a2e2-6317-4134-8ef8-8e3775c5e49b',\n",
       " 'cf78ccc7-edfe-4ac6-be93-f64db197f890',\n",
       " '07f0cd44-64b0-4055-837d-1795b77f1a90',\n",
       " '75c37604-41ed-474e-90e2-783eab24d211',\n",
       " '01837808-de0d-4ea6-930a-8af288eeaee4',\n",
       " 'a0c1e156-c573-4701-8d85-a3c341e76855',\n",
       " '8a3a5b7b-78c9-498d-ab7e-9ebff6fb6fc4',\n",
       " '4b47e045-8f0d-4d73-89aa-6f311ee63e07',\n",
       " 'ad8dc8de-3116-405a-8695-892843212bbb',\n",
       " '7f177295-5665-43d9-8715-41aed77e2a2d',\n",
       " '7f8fbd8b-706e-4d29-a6fe-2be203f0c2bf',\n",
       " '2ec59ff3-c8db-4fd4-a857-5546a86d9931',\n",
       " '7c9129b7-e642-4319-a8d9-4d99a908694b',\n",
       " 'b09cc30e-31bf-47dd-9282-32231dff5331',\n",
       " 'a7f9d0f7-c6d2-42c2-bbeb-2a4882e95a88',\n",
       " '04a647b6-7cad-4a43-8bb8-d4bcceecdb96',\n",
       " '64a99d55-d446-44b2-b260-71cf882a0a9d',\n",
       " '01f96e76-e06f-41ae-8da2-a4c84a97a200',\n",
       " 'dd234126-33f0-45a8-a84c-3ba69b28853d',\n",
       " '1be6202e-4249-4d4d-b6f3-300bb0a4b238',\n",
       " '271906e3-ee95-4423-ac36-14c3aa5d1dc4',\n",
       " '2a66eabe-f12e-4f54-89ef-343fcc8214a4',\n",
       " 'c03fa8f8-2a18-4fac-b087-e17ae5fdb28a',\n",
       " '93f55c39-853a-420c-8df1-b334f5c7789a',\n",
       " 'dd6b042b-d40d-460c-8376-61c47078484d',\n",
       " 'e9190f1d-0b4f-4f1e-ab52-c0d1379f5942',\n",
       " '39d0905f-6193-4f52-a09b-49d08b8b9503',\n",
       " '2cd56bc4-0150-4a4c-b7e1-b0636d8dc889',\n",
       " '11365602-b0b8-4b04-9bea-71eb7ed6497d',\n",
       " 'cdf9e85a-febb-4c4b-9e29-90079fd35326',\n",
       " '9830d1a0-943e-4b98-9125-a692999582c6',\n",
       " '6437bec9-3d19-41d7-ade4-7f2fb6e0e8a1',\n",
       " 'ebdaef7f-6e69-4382-ba59-54144d5d7a7e',\n",
       " '3ae1a2ed-dae2-4f7b-9f08-17f2905e5310',\n",
       " 'c8ef7d8f-5931-4d2f-bde0-5d895761f1e8',\n",
       " 'b2d14b06-5f18-4e53-93e0-3a6d6e321c20',\n",
       " '08e5d546-29cd-4bc2-a435-059d0060cdaf',\n",
       " '3c23afa4-1eee-4bed-962c-a4223b518c75',\n",
       " '3d6b3aa4-909f-4e95-adf3-b69e93dbb31f',\n",
       " '1169188d-d681-489c-bf04-91ebad149bc1',\n",
       " '2c5e9f26-e6cc-49a3-8e1c-46034f0c679d',\n",
       " '5aa9fbce-4111-476e-84bc-21959769b2d2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81fa5974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Saved index 'pdfs' to /home/ashmit/work/SEM_VIII/EnhancedRAG/context/faiss_indexes\n"
     ]
    }
   ],
   "source": [
    "vs.save_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfaf2249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Created retriever for 'pdfs' with {'search_type': 'similarity', 'search_kwargs': {'k': 10}}\n"
     ]
    }
   ],
   "source": [
    "retriever = vs.retriever(search_type = \"similarity\", search_kwargs = {\"k\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4088866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.05s, count=8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='2ec59ff3-c8db-4fd4-a857-5546a86d9931', metadata={'producer': 'Skia/PDF m136 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Project_4_Sankalp_Mane.docx', 'source': '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/pdfs/Project_4_Sankalp_Mane.pdf', 'total_pages': 23, 'page': 3, 'page_label': '4', 'chunk_index': 0, 'tokenizer': 'sentence-transformers/all-mpnet-base-v2', 'tokens': 184}, page_content='acknowledgement i am highly grateful to dr. soharab hossain, associate professor and dr. sandeep kumar, assistant professor at bml munjal university, gurugram, for providing supervision to carry out the seminar / case study from aug - december 2024. dr. soharab and dr. sandeep have provided great help in carrying out my work and is acknowledged with reverential thanks. without wise counsel and able guidance, it would have been impossible to complete the training in this manner. i would like to express thanks profusely to thank dr. soharab and dr. sandeep for stimulating me from time to time. i would also like to thank the entire team at bml munjal university. i would also like to thank my friends who devoted their valuable time and helped me in all possible ways toward successful completion. sankalp mane 4'),\n",
       " Document(id='7f177295-5665-43d9-8715-41aed77e2a2d', metadata={'producer': 'Skia/PDF m136 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Project_4_Sankalp_Mane.docx', 'source': '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/pdfs/Project_4_Sankalp_Mane.pdf', 'total_pages': 23, 'page': 1, 'page_label': '2', 'chunk_index': 0, 'tokenizer': 'sentence-transformers/all-mpnet-base-v2', 'tokens': 185}, page_content='candidate ‚Äô s declaration i hereby certify that the work on the project entitled, ‚Äù project name - automated call transcript summarization and event extraction using speaker diarization and llms ‚Äù, in partial fulfillment of requirements for the award of degree of bachelor of technology in school of engineering and technology at bml munjal university, having university roll no. 210c2030032, is an authentic record of my own work carried out during a period from july 2024 to december 2024 under the supervision of dr. soharab hossain and dr. sandeep kumar sankalp mane ( 210216 ) supervisor ‚Äô s declaration this is to certify that the above statement made by the candidate is correct to the best of my knowledge. faculty supervisor name : dr. soharab hossain signature : faculty supervisor name : dr. sandeep kumar signature : 2'),\n",
       " Document(id='4b47e045-8f0d-4d73-89aa-6f311ee63e07', metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 13.0 (Macintosh)', 'creationdate': '2018-02-23T07:29:33+07:00', 'moddate': '2018-02-23T07:29:40+07:00', 'trapped': '/False', 'source': '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/pdfs/Graph_Databases_for_Beginners.pdf', 'total_pages': 46, 'page': 45, 'page_label': '46', 'chunk_index': 1, 'tokenizer': 'sentence-transformers/all-mpnet-base-v2', 'tokens': 203}, page_content='- time recommendations, graph - based search or supply - chain management, be sure to review all the different ways in which graph technology can work for your company. and while our customers span several continents and professional fields, they all agree that using the neo4j graph database is a critical component of their business success and competitiveness. are you a developer eager to learn more about making the switch? with so many ways to quickly get started, mastering graph database development is one of the best time investments you can make. other resources videos : ‚Ä¢ intro to neo4j and graph databases ‚Ä¢ intro to graph databases episode # 1 - evolution of dbs books : ‚Ä¢ o ‚Äô reilly book : graph databases ‚Ä¢ learning neo4j trainings : ‚Ä¢ online training : getting started with neo4j ‚Ä¢ classroom trainings whether you need a solution that provides real - time recommendations, graph - based search or supply - chain management, be sure to review all the different ways in which graph technology can work for your company.'),\n",
       " Document(id='5aa9fbce-4111-476e-84bc-21959769b2d2', metadata={'source': '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/pdfs/requirements.txt', 'chunk_index': 0, 'tokenizer': 'sentence-transformers/all-mpnet-base-v2', 'tokens': 36}, page_content='langchain - openai langchain - text - splitters sentence - transformers langchain - community unstructured pdfminer pydantic - settings'),\n",
       " Document(id='3b97ca16-eebb-44b0-ae76-639802a1fd19', metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 13.0 (Macintosh)', 'creationdate': '2018-02-23T07:29:33+07:00', 'moddate': '2018-02-23T07:29:40+07:00', 'trapped': '/False', 'source': '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/pdfs/Graph_Databases_for_Beginners.pdf', 'total_pages': 46, 'page': 18, 'page_label': '19', 'chunk_index': 1, 'tokenizer': 'sentence-transformers/all-mpnet-base-v2', 'tokens': 131}, page_content='data, especially if they ‚Äô re tackling a graph - based problem. if your team comes from an sql background, a query language like cypher will be easy to learn and even easier to execute. and when it comes to your enterprise - level application, you ‚Äô ll be glad that the language underpinning it all is build for speed and efficiency. if your team comes from an sql background, a query language like cypher will be easy to learn and even easier to execute. and when it comes to your enterprise - level application, you ‚Äô ll be glad that the language underpinning it all is build for speed and efficiency.'),\n",
       " Document(id='d5130b79-c44b-45e9-a6e8-ed7e18f95921', metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 13.0 (Macintosh)', 'creationdate': '2018-02-23T07:29:33+07:00', 'moddate': '2018-02-23T07:29:40+07:00', 'trapped': '/False', 'source': '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/pdfs/Graph_Databases_for_Beginners.pdf', 'total_pages': 46, 'page': 8, 'page_label': '9', 'chunk_index': 0, 'tokenizer': 'sentence-transformers/all-mpnet-base-v2', 'tokens': 386}, page_content='neo4j. com 8 graph databases for beginners neo4j. com 8 id : vm 10 status : up / down vm : asset id : vm 11 status : up / down vm : asset id : vm 20 status : up / down vm : asset id : vm 30 status : up / down vm : asset id : vm 31 status : up / down vm : asset id : app 1 status : up / down app : asset id : app 2 status : up / down app : asset id : app 3 status : up / down name : user 3 app : asset id : server 1 status : up / down server asset id : server 2 status : up / down server asset id : server 3 status : up / down server asset id : rack 1 status : up / down rack asset id : rack 2 status : up / down rack asset id : loadbalancer 1 status : up / down loadbalancer asset id : loadbalancer 2 status : up / down loadbalancer asset id : database server 1 status : up / down database : asset id : database server 2 status : up / down database : asset id : database server 3 status : up / down database : asset slave _ of slave _ of uses hosted _ byhosted _ byhosted _ byhosted _ by in in in in inin user _ of hosted _ by usesuses runs _ on runs _ on runs _ on runs _ on runs _ on figure 3. 3 : our enriched data model with added labels, attributes and relationships. why data modeling isn ‚Äô t a one - off activity it ‚Äô s easy to dismiss the major differences in data modeling between relational and graph databases. after all, data modeling is just an activity you have to complete once at the beginning of your application development ‚Äì right? wrong. systems change, and in today ‚Äô s development world'),\n",
       " Document(id='7211ebd7-9c3b-4bf4-9ca4-447db1af927e', metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 13.0 (Macintosh)', 'creationdate': '2018-02-23T07:29:33+07:00', 'moddate': '2018-02-23T07:29:40+07:00', 'trapped': '/False', 'source': '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/pdfs/Graph_Databases_for_Beginners.pdf', 'total_pages': 46, 'page': 0, 'page_label': '1', 'chunk_index': 0, 'tokenizer': 'sentence-transformers/all-mpnet-base-v2', 'tokens': 32}, page_content='the # 1 platform for connected data neo4j. com ebook graph databases for beginners bryce merkl sasaki, joy chao & rachel howard'),\n",
       " Document(id='094658bb-ab7d-4b74-8187-c15d4f2a08f3', metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 13.0 (Macintosh)', 'creationdate': '2018-02-23T07:29:33+07:00', 'moddate': '2018-02-23T07:29:40+07:00', 'trapped': '/False', 'source': '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/pdfs/Graph_Databases_for_Beginners.pdf', 'total_pages': 46, 'page': 23, 'page_label': '24', 'chunk_index': 0, 'tokenizer': 'sentence-transformers/all-mpnet-base-v2', 'tokens': 386}, page_content='neo4j. com 23 graph databases for beginners neo4j. com 23 balanced closures help with predictive modeling in graphs. the simple action of searching for chances to create balanced closures allows for the modification of the graph structure for accurate predictive analysis. local bridges we can go further and gain more valuable insight into the communications flow of our organizations by looking at local bridges. these refer to a tie between two nodes where the endpoints of the local bridge are not otherwise connected, nor do they share any common neighbors. you can think of local bridges as connections between two distinct clusters of the graph. in this case, one of the ties has to be weak. for example, the concept of weak links is relevant in algorithms for job search. studies have shown that the best sources of jobs come from looser acquaintances rather than close friends. this is because closer friends tend to share a similar world - view ( are in the same graph component ) but looser friends across a local bridge are in a different social network ( and are in a different graph component ). smaller size bob charlie alice works _ with manages manages edward frances davina peer _ of manages manages peer _ of figure 7. 7 : alice and davina are connected by a local bridge but belong to different graph components. in the image above, davina and alice are connected by a local bridge but belong to different graph components. if davina were to look for a new job, she would be more likely to find a successful recommendation from alice than from frances. this property of local bridges being weak links is something that is found throughout social graphs. as a result, we can make predictive analyses based on empirically derived local bridges and strong triadic closure notions. the final takeaway while graphs and our understanding of them are rooted in hundreds of years of study, we continue to find new ways to apply them to our personal, social'),\n",
       " Document(id='b1e63e40-6dd6-48cf-ae0f-0d14fd957cac', metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 13.0 (Macintosh)', 'creationdate': '2018-02-23T07:29:33+07:00', 'moddate': '2018-02-23T07:29:40+07:00', 'trapped': '/False', 'source': '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/pdfs/Graph_Databases_for_Beginners.pdf', 'total_pages': 46, 'page': 18, 'page_label': '19', 'chunk_index': 0, 'tokenizer': 'sentence-transformers/all-mpnet-base-v2', 'tokens': 386}, page_content='neo4j. com 18 graph databases for beginners neo4j. com 18 delete / remove removes nodes, relationships, and properties. set sets property values and labels. order by sorts results as part of a return. skip limit skip results at the top and limit the number of results. foreach performs an updating action for each element in a list. union merges results from two or more queries. with chains subsequent query parts and forwards results from one to the next. similar to piping commands in unix. if these clauses look familiar ‚Äì especially if you ‚Äô re a sql developer ‚Äì that ‚Äô s great! cypher is intended to be easy - to - learn for sql veterans while also being easy for beginners. ( click here for the most up - to - date cypher refcard to take a deeper dive into the cypher query language. ) at the same time, cypher is different enough to emphasize that we ‚Äô re dealing with graphs, not relational sets. other query languages cypher isn ‚Äô t the only graph database query language ; other graph databases have their own means of querying data as well. many, including neo4j, support the rdf query language sparql and the partially - imperative, path - based query language gremlin. conclusion not everyone gets hands - on with their database query language on the day - to - day level ; however, your down - in - the - weeds development team needs a practical way of modeling and querying data, especially if they ‚Äô re tackling a graph - based problem. if your team comes from an sql background, a query language like cypher will be easy to learn and even easier to execute. and when it comes to your enterprise - level application, you ‚Äô ll be glad that the language underpinning it all is build for speed and efficiency. if your team comes from an sql background'),\n",
       " Document(id='ebdaef7f-6e69-4382-ba59-54144d5d7a7e', metadata={'producer': 'Skia/PDF m136 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Project_4_Sankalp_Mane.docx', 'source': '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/pdfs/Project_4_Sankalp_Mane.pdf', 'total_pages': 23, 'page': 18, 'page_label': '19', 'chunk_index': 0, 'tokenizer': 'sentence-transformers/all-mpnet-base-v2', 'tokens': 17}, page_content='fig 5. 5. 6. : query answering and task scheduling command 19')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"projects by snakalp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c49867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cb8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.ModelLister import HuggingFaceModelLister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3882410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] list_models: time=0.32s, count=10\n"
     ]
    }
   ],
   "source": [
    "lister = HuggingFaceModelLister()\n",
    "\n",
    "models = lister.list_models(task=\"text-generation\",filter=\"text-generation-inference\",inference=\"warm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95bb1384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bigscience/bloom',\n",
       " 'microsoft/phi-2',\n",
       " 'Qwen/QwQ-32B',\n",
       " 'openai-community/gpt2',\n",
       " 'tiiuae/falcon-40b',\n",
       " 'nvidia/Llama-3.1-Nemotron-70B-Instruct-HF',\n",
       " 'microsoft/phi-4',\n",
       " 'databricks/dolly-v2-12b',\n",
       " 'Qwen/Qwen2.5-Coder-32B-Instruct',\n",
       " 'Qwen/QwQ-32B-Preview']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb2d4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "(Request ID: Root=1-680dc39d-354fddbb602f215f3923108f;edafa828-830d-4213-b8db-ec8700e37721)\n\n403 Forbidden: None.\nCannot access content at: https://router.huggingface.co/hf-inference/models/microsoft/phi-4/v1/chat/completions.\nMake sure your token has the correct permissions.\nThe model microsoft/phi-4 is too large to be loaded automatically (29GB > 10GB).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/SEM_VIII/EnhancedRAG/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/SEM_VIII/EnhancedRAG/.venv/lib/python3.12/site-packages/requests/models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://router.huggingface.co/hf-inference/models/microsoft/phi-4/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m client = InferenceClient(\n\u001b[32m      2\u001b[39m     provider=\u001b[33m\"\u001b[39m\u001b[33mhf-inference\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     api_key=settings.HF_TOKEN.get_secret_value(),\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m completion = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicrosoft/phi-4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the capital of France?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/SEM_VIII/EnhancedRAG/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:992\u001b[39m, in \u001b[36mInferenceClient.chat_completion\u001b[39m\u001b[34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[39m\n\u001b[32m    964\u001b[39m parameters = {\n\u001b[32m    965\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: payload_model,\n\u001b[32m    966\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   (...)\u001b[39m\u001b[32m    983\u001b[39m     **(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    984\u001b[39m }\n\u001b[32m    985\u001b[39m request_parameters = provider_helper.prepare_request(\n\u001b[32m    986\u001b[39m     inputs=messages,\n\u001b[32m    987\u001b[39m     parameters=parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    990\u001b[39m     api_key=\u001b[38;5;28mself\u001b[39m.token,\n\u001b[32m    991\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m992\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/SEM_VIII/EnhancedRAG/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:357\u001b[39m, in \u001b[36mInferenceClient._inner_post\u001b[39m\u001b[34m(self, request_parameters, stream)\u001b[39m\n\u001b[32m    354\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.iter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response.content\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/SEM_VIII/EnhancedRAG/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:473\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m403\u001b[39m:\n\u001b[32m    468\u001b[39m     message = (\n\u001b[32m    469\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    470\u001b[39m         + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    471\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure your token has the correct permissions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    472\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m416\u001b[39m:\n\u001b[32m    476\u001b[39m     range_header = response.request.headers.get(\u001b[33m\"\u001b[39m\u001b[33mRange\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: (Request ID: Root=1-680dc39d-354fddbb602f215f3923108f;edafa828-830d-4213-b8db-ec8700e37721)\n\n403 Forbidden: None.\nCannot access content at: https://router.huggingface.co/hf-inference/models/microsoft/phi-4/v1/chat/completions.\nMake sure your token has the correct permissions.\nThe model microsoft/phi-4 is too large to be loaded automatically (29GB > 10GB)."
     ]
    }
   ],
   "source": [
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=settings.HF_TOKEN.get_secret_value(),\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the capital of France?\"\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd682de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionOutput(choices=[ChatCompletionOutputComplete(finish_reason='stop', index=0, message=ChatCompletionOutputMessage(role='assistant', content='The capital of France is **Paris**.', tool_call_id=None, tool_calls=None), logprobs=None)], created=1745731031, id='', model='nvidia/Llama-3.1-Nemotron-70B-Instruct-HF', system_fingerprint='3.2.1-sha-4d28897', usage=ChatCompletionOutputUsage(completion_tokens=10, prompt_tokens=22, total_tokens=32), object='chat.completion')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af85f277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b27500f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.usage.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce481ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
