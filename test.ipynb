{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790fc5b8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0ede3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e277896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.settings import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03cd1b",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ebce362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.DocumentLoader import DocumentLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d929d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DocumentLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc4b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a6e2ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] list_filenames: time=0.00s, count=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Attention_is_all_you_need.pdf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = loader.list_filenames(folder_name)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc70f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] load_documents: time=0.94s, count=15\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load_documents(subdir=folder_name,file_names=files)\n",
    "# print(type(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab29a38c",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e57f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.DocumentChunker import DocumentChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a577bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = DocumentChunker(\n",
    "    hf_embedding_model=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88279a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] chunk_documents: time=0.05s, count=36\n",
      "[METRICS] get_docs_token_count: time=0.02s, count=36\n"
     ]
    }
   ],
   "source": [
    "chunks = chunker.chunk_documents(docs)\n",
    "token_count = chunker.get_docs_token_count(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9a4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "11497\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538524c",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e342810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.HuggingFaceEmbedder import HuggingFaceEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c0268db",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = HuggingFaceEmbedder(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "060fd8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.89s, count=386\n",
      "dimension 768\n"
     ]
    }
   ],
   "source": [
    "v1  = embedder.embed_query(chunks[0].page_content)\n",
    "print(\"dimension\",len(v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db6a20",
   "metadata": {},
   "source": [
    "### Vector Store Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67633625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.VectorStoreManager import VectorStoreManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ace27c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:VectorStoreManager initialized for index 'index'\n"
     ]
    }
   ],
   "source": [
    "vsm = VectorStoreManager(embedding_function=embedder,index_name=folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62ce72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Created FAISS index 'index' with dim=768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.07s, count=4\n"
     ]
    }
   ],
   "source": [
    "vsm.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd1b5100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.HuggingFaceEmbedder:Embedding 36 documents with model 'sentence-transformers/all-mpnet-base-v2'\n",
      "INFO:src.ingestion.HuggingFaceEmbedder:Successfully embedded 36/36 documents\n",
      "INFO:src.ingestion.VectorStoreManager:Added 36 documents to 'index'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_documents: time=15.94s, count=11497\n",
      "[METRICS] add_documents: time=15.97s, count=36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['f3932688-275c-48ca-902c-b186fbd99e26',\n",
       " '74e2e924-4ce4-4384-958d-3a7e341ccf81',\n",
       " 'a29630f8-64a8-4131-9309-fcbdefc6129f',\n",
       " 'b6e1cbc1-f624-4df4-9f4f-997485846718',\n",
       " 'c6885dcd-917b-4edd-8e2d-0152cc0f2419',\n",
       " '88f17933-f4d6-4c34-9336-2ccc365ac3f9',\n",
       " '2c647bd8-8ade-443c-9bf6-b645aa98f9ba',\n",
       " '12c0afc5-4150-4e42-b316-da4359d717a2',\n",
       " 'cbb595be-e718-46e5-ae45-947edaf741c2',\n",
       " '04304937-f9a7-4b6d-a0e2-de8d387dc5a1',\n",
       " '94b6971d-3937-4a0b-b547-f1733314b1bc',\n",
       " '705c0175-1c75-4428-90e9-055eee2ddb1a',\n",
       " '93ae4c99-c91e-4479-abd7-d5fa12f63979',\n",
       " 'c3180194-44d4-47ff-8849-110f71fb243a',\n",
       " 'd9f864e2-00c1-490c-ad0c-aded3c5eefb0',\n",
       " '555036f1-a45c-4ece-a4fb-b4eccd389784',\n",
       " 'ff9f741f-241c-4148-ad32-829c88ae09a6',\n",
       " '760b265c-3656-4730-a69c-6bbe4b51f595',\n",
       " '660ac5b9-9d97-41d8-a232-05d1762509a3',\n",
       " '19835973-7388-48f3-b53d-1b20a0d7108d',\n",
       " '46278085-4ac2-4a6f-b019-a512c0885f03',\n",
       " '15ee65b4-61cb-44ec-a017-cd06db2cf91b',\n",
       " '54bdd885-e918-4933-a037-537ad7cc46ad',\n",
       " '3c5fc77a-ea4e-4cc6-81fb-f9cc1bce8458',\n",
       " 'aa0fdb82-b583-480e-866a-dcbddf286040',\n",
       " 'b27fb132-bf8c-46c7-bde3-0d0a4ac0535f',\n",
       " 'a01eb587-d4a0-4496-bd6e-01ca40dcb2bd',\n",
       " '55cbdc2d-813c-43d7-8d42-d7214ab6d8c2',\n",
       " '5e287892-c630-4a0c-b143-100ba5172546',\n",
       " '4164229a-2473-446d-82ca-e61913456815',\n",
       " 'ead88bbc-8067-4848-b2d4-a2bcda8d10d6',\n",
       " '1013e8b3-fd4d-47a5-9a22-30133d00e317',\n",
       " '6ab3fdf2-e228-4b18-b1b2-fb8d765aa391',\n",
       " '2d93acaa-124c-43f6-96f1-ca7e85572a77',\n",
       " '00ba509d-0e55-4b40-8b57-8b1f56bd8fa9',\n",
       " '9837b769-7693-4383-a877-3cef18f7a6d8']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vsm.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vsm.save_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vsm.load_local(allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5d957",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8afcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved = vsm.similarity_search_with_score(query=\"experience at dolf\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vsm.retriever(search_type = \"similarity\", search_kwargs = {\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4088866",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved = retriever.invoke(\"projects by snakalp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc659565",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [ret.page_content for ret in retrieved]\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fedc8e",
   "metadata": {},
   "source": [
    "### Supported LLMs (as of 06/05/2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebcd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_llms=[\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9368be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from config.settings import settings\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=settings.HF_TOKEN.get_secret_value(),\n",
    ")\n",
    "\n",
    "def get_answer(\n",
    "    sys_prompt: str,\n",
    "    query: str,\n",
    "    model: str = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Send a system + user prompt to the specified model via HF Inference,\n",
    "    returning the assistant’s content string.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\",   \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed623fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_answer(sys_prompt=\"you are a helpful assistant who answers the users query concisely\", query=\"what are the top houses in game of thrones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53079b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answer(sys_prompt=\"you are a helpful assistant who answers the users query concisely\", query=\"what are the top houses in game of thrones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e802c",
   "metadata": {},
   "source": [
    "### Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce481ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.HuggingFaceLLM import HuggingFaceLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd369d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_llm = HuggingFaceLLM(model_name=\"meta-llama/Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9663d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg_llm.get_answer(sys_prompt=\"you are a helpful assistant that answers concisely\", user_prompt=\"what is quantum computing ?\", max_tokens = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.PromptAugmentor import PromptAugmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = PromptAugmentor(client=pg_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = augmentor.generate(query=\"what is a graph db and how is it different from a regular VectorDB ?\", synthetic_count=4)\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "prompt_chunks = []\n",
    "for p in tqdm(prompts, desc=\"Retrieving chunks\", unit=\"prompts\"):\n",
    "    docs = retriever.invoke(p)\n",
    "    prompt_chunks.append((p, docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d93531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.Fusion import FusionSummarizer\n",
    "from src.generation.Prompts import Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_summarizer = FusionSummarizer(fusion_llm=pg_llm,sys_prompt=Prompts.MERGE_FUSION_SYS_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = fusion_summarizer.summarize(prompt_chunks=prompt_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9858267",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summaries = \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_llm = HuggingFaceLLM(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer = final_llm.get_answer(sys_prompt=Prompts.FINAL_ANS_SYS_PROMPT,user_prompt=\"User Question: \\nwhat is a graph db and how is it different from a regular VectorDB ? \\n\\n Context: \\n\"+all_summaries,max_tokens = 400, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fdbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
