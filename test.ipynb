{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790fc5b8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0ede3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e277896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.settings import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03cd1b",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ebce362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.DocumentLoader import DocumentLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d929d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DocumentLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc4b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a6e2ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] list_filenames: time=0.00s, count=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graph_Databases_for_Beginners.pdf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = loader.list_filenames(folder_name)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc70f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5551c4d7274ee49e1f1944ffaaf146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Files:   0%|          | 0/1 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] load_documents: time=2.80s, count=46\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load_documents(subdir=folder_name,file_names=files)\n",
    "# print(type(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab29a38c",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e57f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.DocumentChunker import DocumentChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a577bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = DocumentChunker(\n",
    "    hf_embedding_model=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88279a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bf66319a3649edb95896b049bdbc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunking documents:   0%|          | 0/46 [00:00<?, ?doc/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] chunk_documents: time=0.47s, count=88\n",
      "[METRICS] get_docs_token_count: time=0.18s, count=88\n"
     ]
    }
   ],
   "source": [
    "chunks = chunker.chunk_documents(docs)\n",
    "token_count = chunker.get_docs_token_count(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9a4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "26370\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538524c",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e342810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.HuggingFaceEmbedder import HuggingFaceEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c0268db",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = HuggingFaceEmbedder(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "060fd8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.12s, count=32\n",
      "dimension 768\n"
     ]
    }
   ],
   "source": [
    "v1  = embedder.embed_query(chunks[0].page_content)\n",
    "print(\"dimension\",len(v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db6a20",
   "metadata": {},
   "source": [
    "### Vector Store Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67633625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.VectorStoreManager import VectorStoreManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ace27c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:VectorStoreManager initialized for index 'index'\n"
     ]
    }
   ],
   "source": [
    "vsm = VectorStoreManager(embedding_function=embedder,index_name=folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62ce72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Created FAISS index 'index' with dim=768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.13s, count=4\n"
     ]
    }
   ],
   "source": [
    "vsm.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsm.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa5974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Saved index 'index' to '/home/ashmit/work/SEM_VIII/EnhancedRAG/context/faiss_indexes'\n"
     ]
    }
   ],
   "source": [
    "# vsm.save_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5bb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Loaded index 'index' from disk\n"
     ]
    }
   ],
   "source": [
    "# vsm.load_local(allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5d957",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d8afcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.08s, count=6\n",
      "[METRICS] similarity_search_with_score: time=0.09s, count=2\n"
     ]
    }
   ],
   "source": [
    "retrieved = vsm.similarity_search_with_score(query=\"experience at dolf\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfaf2249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Created retriever for 'index' with {'search_type': 'similarity', 'search_kwargs': {'k': 2}}\n"
     ]
    }
   ],
   "source": [
    "retriever = vsm.retriever(search_type = \"similarity\", search_kwargs = {\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4088866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.17s, count=8\n"
     ]
    }
   ],
   "source": [
    "retrieved = retriever.invoke(\"projects by snakalp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc659565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- time recommendations, graph - based search or supply - chain management, be sure to review all the different ways in which graph technology can work for your company. and while our customers span several continents and professional fields, they all agree that using the neo4j graph database is a critical component of their business success and competitiveness. are you a developer eager to learn more about making the switch? with so many ways to quickly get started, mastering graph database development is one of the best time investments you can make. other resources videos : • intro to neo4j and graph databases • intro to graph databases episode # 1 - evolution of dbs books : • o ’ reilly book : graph databases • learning neo4j trainings : • online training : getting started with neo4j • classroom trainings whether you need a solution that provides real - time recommendations, graph - based search or supply - chain management, be sure to review all the different ways in which graph technology can work for your company.',\n",
       " 'data, especially if they ’ re tackling a graph - based problem. if your team comes from an sql background, a query language like cypher will be easy to learn and even easier to execute. and when it comes to your enterprise - level application, you ’ ll be glad that the language underpinning it all is build for speed and efficiency. if your team comes from an sql background, a query language like cypher will be easy to learn and even easier to execute. and when it comes to your enterprise - level application, you ’ ll be glad that the language underpinning it all is build for speed and efficiency.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [ret.page_content for ret in retrieved]\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fedc8e",
   "metadata": {},
   "source": [
    "### Supported LLMs (as of 06/05/2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebcd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_llms=[\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9368be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from config.settings import settings\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=settings.HF_TOKEN.get_secret_value(),\n",
    ")\n",
    "\n",
    "def get_answer(\n",
    "    sys_prompt: str,\n",
    "    query: str,\n",
    "    model: str = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Send a system + user prompt to the specified model via HF Inference,\n",
    "    returning the assistant’s content string.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\",   \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed623fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_answer(sys_prompt=\"you are a helpful assistant who answers the users query concisely\", query=\"what are the top houses in game of thrones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionOutputMessage(role='assistant', content='A concise question about Westeros! Here are the **Top Houses in Game of Thrones**, in no particular order, along with their **Sigil**, **Motto**, and **Seat of Power**:\\n\\n1. **House Stark**\\n\\t* Sigil: Direwolf\\n\\t* Motto: \"Winter is Coming\"\\n\\t* Seat: Winterfell\\n\\n2. **House Lannister**\\n\\t* Sigil: Lion\\n\\t* Motto: \"Hear Me Roar!\"\\n\\t* Seat: Casterly Rock\\n\\n3. **House Targaryen**\\n\\t* Sigil: Dragon\\n\\t* Motto: \"Fire and Blood\"\\n\\t* Seat: Dragonstone (formerly King\\'s Landing)\\n\\n4. **House Tyrell**\\n\\t* Sigil: Rose\\n\\t* Motto: \"Growing Strong\"\\n\\t* Seat: Highgarden\\n\\n5. **House Greyjoy**\\n\\t* Sigil: Kraken\\n\\t* Motto: \"We Do Not Sow\"\\n\\t* Seat: Pyke\\n\\n6. **House Baratheon**\\n\\t* Sigil: Stag\\n\\t* Motto: \"Ours is the Fury\"\\n\\t* Seats: Storm\\'s End (original), King\\'s Landing (during Robert\\'s reign), Dragonstone (Stannis\\' faction)\\n\\n7. **House Arryn**\\n\\t* Sigil: Falcon\\n\\t* Motto: \"As High as Honor\"\\n\\t* Seat: The Eyrie\\n\\n8. **House Martell**\\n\\t* Sigil: Spear\\n\\t* Motto: \"Unbowed, Unbent, Unbroken\"\\n\\t* Seat: Sunspear\\n\\nThese houses play pivotal roles in the Game of Thrones series. Note that the influence and power of each house fluctuate throughout the storyline.', tool_call_id=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01a5776d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A concise question about Westeros! Here are the **Top Houses in Game of Thrones**, in no particular order, highlighting their **Sigil**, **Motto**, and **Notable Members**:\\n\\n1. **House Stark**\\n\\t* **Sigil**: Direwolf\\n\\t* **Motto**: \"Winter is Coming\"\\n\\t* **Notable Members**: Eddard (Ned), Robb, Sansa, Arya, Bran, Jon Snow\\n\\n2. **House Lannister**\\n\\t* **Sigil**: Lion\\n\\t* **Motto**: \"Hear Me Roar!\"\\n\\t* **Notable Members**: Cersei, Jaime, Tyrion, Tywin, Kevan\\n\\n3. **House Targaryen**\\n\\t* **Sigil**: Dragon\\n\\t* **Motto**: \"Fire and Blood\"\\n\\t* **Notable Members**: Daenerys, Viserys, Rhaegar, Aerys II (Mad King), Jon Snow (Aegon Targaryen)\\n\\n4. **House Baratheon**\\n\\t* **Sigil**: Stag\\n\\t* **Motto**: \"Ours is the Fury\"\\n\\t* **Notable Members**: Robert, Stannis, Renly, Joffrey, Myrcella, Tommen\\n\\n5. **House Tyrell**\\n\\t* **Sigil**: Rose\\n\\t* **Motto**: \"Growing Strong\"\\n\\t* **Notable Members**: Mace, Loras, Margaery, Olenna (Queen of Thorns)\\n\\n6. **House Greyjoy**\\n\\t* **Sigil**: Kraken\\n\\t* **Motto**: \"We Do Not Sow\"\\n\\t* **Notable Members**: Balon, Yara, Theon, Euron\\n\\n7. **House Arryn**\\n\\t* **Sigil**: Falcon\\n\\t* **Motto**: \"As High as Honor\"\\n\\t* **Notable Members**: Jon Arryn, Lysa, Robin, Yohn Royce (conditional ally)\\n\\n8. **House Martell**\\n\\t* **Sigil**: Spear\\n\\t* **Motto**: \"Unbowed, Unbent, Unbroken\"\\n\\t* **Notable Members**: Oberyn, Ellaria, Doran, Trystane, Arianne\\n\\nThese houses are central to the plot and power struggles throughout the series. Of course, there are many other influential houses in the world of Game of Thrones, but these are generally considered the most pivotal.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(sys_prompt=\"you are a helpful assistant who answers the users query concisely\", query=\"what are the top houses in game of thrones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e802c",
   "metadata": {},
   "source": [
    "### Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce481ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.HuggingFaceLLM import HuggingFaceLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd369d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.generation.HuggingFaceLLM:Creating new HuggingFaceLLM for model: meta-llama/Llama-3.1-8B-Instruct\n",
      "INFO:src.generation.HuggingFaceLLM:InferenceClient initialized for model: meta-llama/Llama-3.1-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "pg_llm = HuggingFaceLLM(model_name=\"meta-llama/Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9663d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg_llm.get_answer(sys_prompt=\"you are a helpful assistant that answers concisely\", user_prompt=\"what is quantum computing ?\", max_tokens = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3192ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.PromptAugmentor import PromptAugmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78dd5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = PromptAugmentor(client=pg_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3aad6d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc46c0f938a943f08be214a37002a344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating prompts:   0%|          | 0/4 [00:00<?, ?prompt/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.generation.PromptAugmentor:Requesting synthetic prompt 1/4\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 124 characters\n",
      "INFO:src.generation.PromptAugmentor:Generated prompt #1: 'What is the key difference between a Graph Database and a Vector Database in terms of data structure and query capabilities?'\n",
      "INFO:src.generation.PromptAugmentor:Requesting synthetic prompt 2/4\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 96 characters\n",
      "INFO:src.generation.PromptAugmentor:Generated prompt #2: 'What are the primary use cases for Graph Databases compared to traditional relational databases?'\n",
      "INFO:src.generation.PromptAugmentor:Requesting synthetic prompt 3/4\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 141 characters\n",
      "INFO:src.generation.PromptAugmentor:Generated prompt #3: \"What are the key advantages of using a Graph Database for complex relationships compared to a Vector Database's similarity-based connections?\"\n",
      "INFO:src.generation.PromptAugmentor:Requesting synthetic prompt 4/4\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 161 characters\n",
      "INFO:src.generation.PromptAugmentor:Generated prompt #4: 'What are the primary data modeling and querying paradigms that distinguish a Graph Database from a Vector Database in terms of data representation and retrieval?'\n",
      "INFO:src.generation.PromptAugmentor:Prompt generation completed with 5 prompts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is the key difference between a Graph Database and a Vector Database in terms of data structure and query capabilities?',\n",
       " 'What are the primary use cases for Graph Databases compared to traditional relational databases?',\n",
       " \"What are the key advantages of using a Graph Database for complex relationships compared to a Vector Database's similarity-based connections?\",\n",
       " 'What are the primary data modeling and querying paradigms that distinguish a Graph Database from a Vector Database in terms of data representation and retrieval?',\n",
       " 'what is a graph db and how is it different from a regular VectorDB ?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = augmentor.generate(query=\"what is a graph db and how is it different from a regular VectorDB ?\", synthetic_count=4)\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "619c97da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db38ba8441314db291cd8f60216b76a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving chunks:   0%|          | 0/5 [00:00<?, ?prompts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.28s, count=24\n",
      "[METRICS] embed_query: time=0.22s, count=17\n",
      "[METRICS] embed_query: time=0.19s, count=27\n",
      "[METRICS] embed_query: time=0.24s, count=30\n",
      "[METRICS] embed_query: time=0.34s, count=18\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "prompt_chunks = []\n",
    "for p in tqdm(prompts, desc=\"Retrieving chunks\", unit=\"prompts\"):\n",
    "    docs = retriever.invoke(p)\n",
    "    prompt_chunks.append((p, docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43d93531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.Fusion import FusionSummarizer\n",
    "from src.generation.Prompts import Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9161b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_summarizer = FusionSummarizer(fusion_llm=pg_llm,sys_prompt=Prompts.MERGE_FUSION_SYS_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72f3d459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.generation.Fusion:Generating summary for prompt 1: 'What is the key difference between a Graph Databas...'\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 1111 characters\n",
      "INFO:src.generation.Fusion:Generating summary for prompt 2: 'What are the primary use cases for Graph Databases...'\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 1111 characters\n",
      "INFO:src.generation.Fusion:Generating summary for prompt 3: 'what is a graph db and how is it different from a ...'\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 1301 characters\n"
     ]
    }
   ],
   "source": [
    "summaries = fusion_summarizer.summarize(prompt_chunks=prompt_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9858267",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summaries = \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "132c3d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.generation.HuggingFaceLLM:Creating new HuggingFaceLLM for model: meta-llama/Llama-3.3-70B-Instruct\n",
      "INFO:src.generation.HuggingFaceLLM:InferenceClient initialized for model: meta-llama/Llama-3.3-70B-Instruct\n"
     ]
    }
   ],
   "source": [
    "final_llm = HuggingFaceLLM(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "607a3b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.3-70B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 599 characters\n"
     ]
    }
   ],
   "source": [
    "final_answer = final_llm.get_answer(sys_prompt=Prompts.FINAL_ANS_SYS_PROMPT,user_prompt=\"User Question: \\nwhat is a graph db and how is it different from a regular VectorDB ? \\n\\n Context: \\n\"+all_summaries,max_tokens = 400, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9fdbccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A graph database is an online, operational database management system that operates on a graph data model, storing data as nodes and relationships. It is different from a regular VectorDB in terms of data model, storage, and processing. Graph databases use a graph data model, native graph storage, and native graph processing, whereas VectorDBs are suited for dense, high-dimensional data and are often used in scenarios such as recommendation systems, image and speech recognition, and Natural Language Processing (NLP). Insufficient information is available to provide a more detailed comparison.\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
