{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790fc5b8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a0ede3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e277896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.loader import DocumentLoader\n",
    "from src.ingestion.chunker import DocumentChunker\n",
    "from src.ingestion.HuggingFaceEmbedder import HuggingFaceEmbedder\n",
    "from config.settings import settings\n",
    "from src.ingestion.VectorStoreManager import VectorStoreManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03cd1b",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d929d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DocumentLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dc4b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6e2ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] list_filenames: time=0.00s, count=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sankalp_Resume.pdf']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = loader.list_filenames(folder_name)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc70f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] load_documents: time=0.28s, count=1\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load_documents(subdir=folder_name,file_names=files)\n",
    "# print(type(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab29a38c",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a577bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = DocumentChunker(\n",
    "    hf_embedding_model=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88279a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] chunk_documents: time=0.01s, count=3\n",
      "[METRICS] get_docs_token_count: time=0.00s, count=3\n"
     ]
    }
   ],
   "source": [
    "chunks = chunker.chunk_documents(docs)\n",
    "token_count = chunker.get_docs_token_count(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9a4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "939\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538524c",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c0268db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "embedder = HuggingFaceEmbedder(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "060fd8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=3.14s, count=386\n",
      "dimension 768\n"
     ]
    }
   ],
   "source": [
    "v1  = embedder.embed_query(chunks[0].page_content)\n",
    "print(\"dimension\",len(v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db6a20",
   "metadata": {},
   "source": [
    "### Vector Store Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ace27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsm = VectorStoreManager(embedding_function=embedder,index_name=folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62ce72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Created in‐memory FAISS index 'index' (dim=768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.20s, count=4\n"
     ]
    }
   ],
   "source": [
    "vsm.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd1b5100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Added 3 docs into 'index'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_documents: time=3.00s, count=939\n",
      "[METRICS] add_documents: time=3.02s, count=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['347d5864-12a0-4a9d-a086-177a355646c2',\n",
       " 'e9edf48f-a286-49a0-9c40-8cd06730c1a9',\n",
       " '317beb41-f504-40e0-868f-1afef9a8ae38']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vsm.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa5974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Saved index 'pdfs' to /home/ashmit/work/SEM_VIII/EnhancedRAG/context/faiss_indexes\n"
     ]
    }
   ],
   "source": [
    "# vsm.save_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d8afcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.23s, count=6\n",
      "[METRICS] similarity_search_with_score: time=0.26s, count=2\n"
     ]
    }
   ],
   "source": [
    "retrieved = vsm.similarity_search_with_score(query=\"experience at dolf\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfaf2249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Created retriever for 'index' with {'search_type': 'similarity', 'search_kwargs': {'k': 2}}\n"
     ]
    }
   ],
   "source": [
    "retriever = vsm.retriever(search_type = \"similarity\", search_kwargs = {\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4088866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.46s, count=8\n"
     ]
    }
   ],
   "source": [
    "retrieved = retriever.invoke(\"projects by snakalp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc659565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sankalp mane mlh hackhound ’ 23 winner, passionate about data science, ml and genai. c manesm2403 @ gmail. com | ħ + 91 91728 67443 | a github. com / sankadash | ] linkedin. com / in / snklpm skills programming languages python, shell, sql, html, css, r tools and technologies numpy, pandas, matplotlib, seaborn, plotly, scikit - learn, transformers, tensorflow, py - torch, keras, openai api, langchain, chromadb, mongodb, flask, linux, git, docker, databricks, microsoft autogen, smolagents experience centific october 2024 - present associate ai engineer intern rag, ai services, databricks, hugging face, openai, langchain • engineered an ai - driven rag fusion system that integrates multi - llm providers ( openai, databricks, hugging face ) via langchain and azure databricks, enabling dynamic query transformation and precise document summarization. • developed and deployed modular ai services including merge fusion, weighted fusion, and ood testing along with pipelines for advanced knowledge retrieval, text understanding, and generation, with robust api integration and comprehensive unit tests. • optimized scalable deployment pipelines using distributed frameworks ( spark, multi - cluster fine - tuning with peft adaptors, runpod, vllm ) and integrated benchmarking tools ( mlflow, tensorboard, weights & biases ), significantly boosting model performance and operational reliability. dolf. finance may 2023 - aug. 2023 summer intern python, flask, openai, chromadb, langchain mongodb, websockets',\n",
       " 'models for accurate question answering. • implemented rigorous preprocessing techniques and trained models over 500 epochs. • achieved 83 % accuracy with pre - trained models like bert and llama. education bml munjal university expected graduation : june 2025 b. tech in computer science and engineering minor in energy harvesting achievements • mlh hackhound ’ 23 winner in ai / ml category. • best collaborator at centific premier ai hackathon, 2024. • placed among the top 10 at the international airship regatta 2022, iit bombay. certifications • introduction to artificial intelligence ( ai ) | ibm • natural language processing with probabilistic models | deeplearning. ai • deep learning applications for computer vision | university of colorado boulder • number theory and cryptography | university of california san diego']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [ret.page_content for ret in retrieved_chunk_docs]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97cca9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.608781337738037"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_summary(prompt: str])->str:\n",
    "    retrieved = vsm.similarity_search_with_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c49867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from config.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67acd1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08cb8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.ModelLister import HuggingFaceModelLister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3882410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] list_models: time=0.42s, count=0\n"
     ]
    }
   ],
   "source": [
    "lister = HuggingFaceModelLister()\n",
    "\n",
    "models = lister.list_models(task=[\"text-generation\",\"tex\"],filter=\"inference-endpoints\",inference=\"warm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354578b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = lister.huggingface_api()\n",
    "\n",
    "models = api.list_models(\n",
    "    sort=\"likes\",\n",
    "    inference=\"warm\",\n",
    "    task=\"text-generation\",\n",
    "    filter=[\"text-generation-inference\",\"HF-Inference-API\"],\n",
    "    gated=False,\n",
    "    limit=5)\n",
    "\n",
    "listed = []\n",
    "for model in models:\n",
    "    listed.append(model)\n",
    "listed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebcd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_llms=[\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61ac3605",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=settings.HF_TOKEN.get_secret_value(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37b7c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\",\n",
    "    messages=[\n",
    "        {\"role\": \"System\", \"content\": \"Answer the question given by the user as concisely and accurately as possible\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "        ],\n",
    "    max_tokens=200,\n",
    ")\n",
    "response = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f9368be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from config.settings import settings\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=settings.HF_TOKEN.get_secret_value(),\n",
    ")\n",
    "\n",
    "def get_answer(\n",
    "    sys_prompt: str,\n",
    "    query: str,\n",
    "    model: str = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Send a system + user prompt to the specified model via HF Inference,\n",
    "    returning the assistant’s content string.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\",   \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01a5776d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A concise question about Westeros! Here are the **Top Houses in Game of Thrones**, in no particular order, highlighting their **Sigil**, **Motto**, and **Notable Members**:\\n\\n1. **House Stark**\\n\\t* **Sigil**: Direwolf\\n\\t* **Motto**: \"Winter is Coming\"\\n\\t* **Notable Members**: Eddard (Ned), Robb, Sansa, Arya, Bran, Jon Snow\\n\\n2. **House Lannister**\\n\\t* **Sigil**: Lion\\n\\t* **Motto**: \"Hear Me Roar!\"\\n\\t* **Notable Members**: Cersei, Jaime, Tyrion, Tywin, Kevan\\n\\n3. **House Targaryen**\\n\\t* **Sigil**: Dragon\\n\\t* **Motto**: \"Fire and Blood\"\\n\\t* **Notable Members**: Daenerys, Viserys, Rhaegar, Aerys II (Mad King), Jon Snow (Aegon Targaryen)\\n\\n4. **House Baratheon**\\n\\t* **Sigil**: Stag\\n\\t* **Motto**: \"Ours is the Fury\"\\n\\t* **Notable Members**: Robert, Stannis, Renly, Joffrey, Myrcella, Tommen\\n\\n5. **House Tyrell**\\n\\t* **Sigil**: Rose\\n\\t* **Motto**: \"Growing Strong\"\\n\\t* **Notable Members**: Mace, Loras, Margaery, Olenna (Queen of Thorns)\\n\\n6. **House Greyjoy**\\n\\t* **Sigil**: Kraken\\n\\t* **Motto**: \"We Do Not Sow\"\\n\\t* **Notable Members**: Balon, Yara, Theon, Euron\\n\\n7. **House Arryn**\\n\\t* **Sigil**: Falcon\\n\\t* **Motto**: \"As High as Honor\"\\n\\t* **Notable Members**: Jon Arryn, Lysa, Robin, Yohn Royce (conditional ally)\\n\\n8. **House Martell**\\n\\t* **Sigil**: Spear\\n\\t* **Motto**: \"Unbowed, Unbent, Unbroken\"\\n\\t* **Notable Members**: Oberyn, Ellaria, Doran, Trystane, Arianne\\n\\nThese houses are central to the plot and power struggles throughout the series. Of course, there are many other influential houses in the world of Game of Thrones, but these are generally considered the most pivotal.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(sys_prompt=\"you are a helpful assistant who answers the users query concisely\", query=\"what are the top houses in game of thrones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b5e83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9cdb2d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Llama-3.1-8B-Instruct → 0.399s: The capital of France is Paris.\n",
      "meta-llama/Llama-3.3-70B-Instruct → 0.791s: The capital of France is Paris.\n",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B → 0.368s: Okay, so I need to figure out what the capital of France is. Hmm, I remember from school that Paris is the capital, but maybe I should double-check to make sure. Let me think about other possible cities in France. There's Lyon, Marseille, and Nice, but those don't sound like capitals. Wait, could it be somewhere else? Maybe Lille or Toulouse? No, those are major cities but I don't think they're capitals. France has a long history, so maybe the capital has changed before. I think historically, Paris has always been the capital, but I'm not entirely sure. I should probably look up some historical context. Oh, and the Eiffel Tower is in Paris, which is a symbol of France, so that reinforces that Paris is the capital. Also, when I think of French government buildings and embassies, they're usually in Paris. Yeah, I think I'm confident now. The capital of France is Paris.\n",
      "</think>\n",
      "mistralai/Mistral-7B-Instruct-v0.3 → 0.443s: The capital of France is Paris. It's one of the most famous cities in the world, known for its rich history, culture, art, and architecture. The French government is headquartered at the Hôtel des Invalides, the Louvre Palace, and most notably, the Eiffel Tower, located in the heart of the city. However, the official seat of the French President is at the Élysée Palace in Paris.\n",
      "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF → 0.354s: The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "inference_x_time = pd.DataFrame(columns=[\"response\", \"time_taken\"])\n",
    "\n",
    "for model in hf_models:\n",
    "    start = time.time()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    "        max_tokens=200,\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    \n",
    "    time_taken = time.time() - start\n",
    "    \n",
    "    next_index = len(inference_x_time)\n",
    "    inference_x_time.loc[next_index] = [response, time_taken]\n",
    "    \n",
    "    print(f\"{model} → {time_taken:.3f}s: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1213fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "      <td>0.399337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "      <td>0.790705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Okay, so I need to figure out what the capital...</td>\n",
       "      <td>0.367647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The capital of France is Paris. It's one of th...</td>\n",
       "      <td>0.443220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The capital of France is **Paris**.</td>\n",
       "      <td>0.353560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  time_taken\n",
       "0                    The capital of France is Paris.    0.399337\n",
       "1                    The capital of France is Paris.    0.790705\n",
       "2  Okay, so I need to figure out what the capital...    0.367647\n",
       "3  The capital of France is Paris. It's one of th...    0.443220\n",
       "4                The capital of France is **Paris**.    0.353560"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(inference_x_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6252bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The capital of France is Paris. It's one of the most famous cities in the world, known for its rich history, culture, art, and architecture. The French government is headquartered at the Hôtel des Invalides, the Louvre Palace, and most notably, the Eiffel Tower, located in the heart of the city. However, the official seat of the French President is at the Élysée Palace in Paris.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_x_time[\"response\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd682de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionOutput(choices=[ChatCompletionOutputComplete(finish_reason='stop', index=0, message=ChatCompletionOutputMessage(role='assistant', content='The capital of France is **Paris**.', tool_call_id=None, tool_calls=None), logprobs=None)], created=1745731031, id='', model='nvidia/Llama-3.1-Nemotron-70B-Instruct-HF', system_fingerprint='3.2.1-sha-4d28897', usage=ChatCompletionOutputUsage(completion_tokens=10, prompt_tokens=22, total_tokens=32), object='chat.completion')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af85f277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b27500f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.usage.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce481ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.HuggingFaceLLM import HuggingFaceLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd369d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_llm = HuggingFaceLLM(model_name=\"meta-llama/Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9663d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quantum computing is a revolutionary computing paradigm that uses the principles of quantum mechanics to process information. Unlike classical computers, which use bits (0s and 1s) to store and process data, quantum computers use quantum bits or qubits.\\n\\nQubits can exist in multiple states simultaneously, allowing quantum computers to:\\n\\n1. Process massive amounts of data in parallel\\n2. Solve complex problems exponentially faster than classical computers\\n\\nThis leads to potential breakthroughs in:\\n\\n1. cryptography\\n2. machine learning\\n3. materials science\\n4. optimization problems\\n\\nHowever, quantum computing is still in its early stages, and significant technical challenges need to be overcome before it becomes widely available.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_llm.get_answer(sys_prompt=\"you are a helpful assistant that answers concisely\", user_prompt=\"what is quantum computing ?\", max_tokens = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3192ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.PromptAugmentor import PromptAugmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78dd5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = PromptAugmentor(client=pg_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aad6d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What did he say to the mother of my child?',\n",
       " 'What did he say to the mother of my child in that conversation.',\n",
       " 'what did he say to that person who is the mother of my child']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = augmentor.generate(query=\"what did he say to that person who is the mother of my child\", synthetic_count=2)\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c97da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
