{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790fc5b8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0ede3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e277896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.settings import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03cd1b",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebce362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.DocumentLoader import DocumentLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d929d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DocumentLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc4b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a6e2ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] list_filenames: time=0.00s, count=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Attention_is_all_you_need.pdf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = loader.list_filenames(folder_name)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bc70f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] load_documents: time=0.81s, count=15\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load_documents(subdir=folder_name,file_names=files)\n",
    "# print(type(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab29a38c",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e57f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.DocumentChunker import DocumentChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a577bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = DocumentChunker(\n",
    "    hf_embedding_model=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88279a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunker.chunk_documents(docs)\n",
    "token_count = chunker.get_docs_token_count(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(chunks))\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538524c",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.HuggingFaceEmbedder import HuggingFaceEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0268db",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = HuggingFaceEmbedder(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fd8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1  = embedder.embed_query(chunks[0].page_content)\n",
    "print(\"dimension\",len(v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db6a20",
   "metadata": {},
   "source": [
    "### Vector Store Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67633625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.VectorStoreManager import VectorStoreManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsm = VectorStoreManager(embedding_function=embedder,index_name=folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsm.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsm.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vsm.save_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vsm.load_local(allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5d957",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8afcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved = vsm.similarity_search_with_score(query=\"experience at dolf\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vsm.retriever(search_type = \"similarity\", search_kwargs = {\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4088866",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved = retriever.invoke(\"projects by snakalp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc659565",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [ret.page_content for ret in retrieved]\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fedc8e",
   "metadata": {},
   "source": [
    "### Supported LLMs (as of 06/05/2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebcd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_llms=[\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9368be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from config.settings import settings\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=settings.HF_TOKEN.get_secret_value(),\n",
    ")\n",
    "\n",
    "def get_answer(\n",
    "    sys_prompt: str,\n",
    "    query: str,\n",
    "    model: str = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Send a system + user prompt to the specified model via HF Inference,\n",
    "    returning the assistantâ€™s content string.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\",   \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed623fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_answer(sys_prompt=\"you are a helpful assistant who answers the users query concisely\", query=\"what are the top houses in game of thrones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53079b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answer(sys_prompt=\"you are a helpful assistant who answers the users query concisely\", query=\"what are the top houses in game of thrones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e802c",
   "metadata": {},
   "source": [
    "### Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce481ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.HuggingFaceLLM import HuggingFaceLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd369d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_llm = HuggingFaceLLM(model_name=\"meta-llama/Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9663d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg_llm.get_answer(sys_prompt=\"you are a helpful assistant that answers concisely\", user_prompt=\"what is quantum computing ?\", max_tokens = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.PromptAugmentor import PromptAugmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = PromptAugmentor(client=pg_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = augmentor.generate(query=\"what is a graph db and how is it different from a regular VectorDB ?\", synthetic_count=4)\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "prompt_chunks = []\n",
    "for p in tqdm(prompts, desc=\"Retrieving chunks\", unit=\"prompts\"):\n",
    "    docs = retriever.invoke(p)\n",
    "    prompt_chunks.append((p, docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d93531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.Fusion import FusionSummarizer\n",
    "from src.generation.Prompts import Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_summarizer = FusionSummarizer(fusion_llm=pg_llm,sys_prompt=Prompts.MERGE_FUSION_SYS_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = fusion_summarizer.summarize(prompt_chunks=prompt_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9858267",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summaries = \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_llm = HuggingFaceLLM(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer = final_llm.get_answer(sys_prompt=Prompts.FINAL_ANS_SYS_PROMPT,user_prompt=\"User Question: \\nwhat is a graph db and how is it different from a regular VectorDB ? \\n\\n Context: \\n\"+all_summaries,max_tokens = 400, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fdbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
