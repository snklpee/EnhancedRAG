{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790fc5b8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a0ede3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e277896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.loader import DocumentLoader\n",
    "from src.ingestion.chunker import DocumentChunker\n",
    "from src.ingestion.HuggingFaceEmbedder import HuggingFaceEmbedder\n",
    "from config.settings import settings\n",
    "from src.ingestion.VectorStoreManager import VectorStoreManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03cd1b",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d929d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DocumentLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dc4b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a6e2ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] list_filenames: time=0.00s, count=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graph_Databases_for_Beginners.pdf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = loader.list_filenames(folder_name)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bc70f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] load_documents: time=2.93s, count=46\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load_documents(subdir=folder_name,file_names=files)\n",
    "# print(type(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab29a38c",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0a577bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "chunker = DocumentChunker(\n",
    "    hf_embedding_model=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88279a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] chunk_documents: time=0.35s, count=88\n",
      "[METRICS] get_docs_token_count: time=0.18s, count=88\n"
     ]
    }
   ],
   "source": [
    "chunks = chunker.chunk_documents(docs)\n",
    "token_count = chunker.get_docs_token_count(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a9a4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "26370\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538524c",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0268db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "embedder = HuggingFaceEmbedder(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "060fd8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.37s, count=32\n",
      "dimension 768\n"
     ]
    }
   ],
   "source": [
    "v1  = embedder.embed_query(chunks[0].page_content)\n",
    "print(\"dimension\",len(v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db6a20",
   "metadata": {},
   "source": [
    "### Vector Store Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ace27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsm = VectorStoreManager(embedding_function=embedder,index_name=folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62ce72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Created in‐memory FAISS index 'index' (dim=768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.16s, count=4\n"
     ]
    }
   ],
   "source": [
    "vsm.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd1b5100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Added 88 docs into 'index'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_documents: time=61.24s, count=26370\n",
      "[METRICS] add_documents: time=61.42s, count=88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3b937cfb-d524-4eb6-8ea7-b83753f6fa8f',\n",
       " '99a1dc26-69b9-4e0d-b56b-add9c7372cd7',\n",
       " 'bb29b478-08d2-4f93-9057-3888b3957d9d',\n",
       " '27f960f4-a0ca-4a45-85ea-8669c2a39fc5',\n",
       " '9e88b23f-10d7-4971-9f4d-aceb7e6ad78d',\n",
       " '86d414aa-9b7f-4d53-8f4c-e1edf1446efe',\n",
       " 'f7cf26dd-039a-4b5a-9abb-dd4d6b5e492a',\n",
       " 'bb2ab7a1-c45e-49f7-8431-f709e4529c7d',\n",
       " 'dfaa63cd-8942-49b4-b55b-e45e91ffdce5',\n",
       " '719d87d3-9108-4d2a-a2b5-deeb65c1ff84',\n",
       " '0d48c7cd-ee07-45b5-998f-44c0e12dd802',\n",
       " 'fa99c4df-c712-452a-9c38-450e0afba6ba',\n",
       " 'd1b3d024-0383-45e5-8efc-360ad5b99099',\n",
       " 'ca051af7-636e-4f55-9979-a8d1a91227fe',\n",
       " '0e602ffe-48df-4d5e-9f35-5bd27ca116ac',\n",
       " 'd97bdbdf-b8cc-4b42-a60f-11a2fb4b6b32',\n",
       " 'e2b58851-c68b-4761-b4f4-c39b6549cb09',\n",
       " 'f8458a07-0fc2-4033-ae89-97f2e92cbb30',\n",
       " '835ff2ce-9257-40be-bb8e-68ee349392d1',\n",
       " '7675e7b7-7a55-446d-bc1a-2e4d7d9f0301',\n",
       " '4ea423b8-8a5d-4815-878d-b554c29c3395',\n",
       " '95194159-0b88-4506-a21b-045d1b6bd34a',\n",
       " '2186d6dc-cb09-4ecc-860e-b9164cff825f',\n",
       " '16f3f66e-a234-4447-b3b9-89fef74d15c7',\n",
       " '2f9c3683-7950-4c20-974b-7443f43db594',\n",
       " '96a227b5-5ac5-4ff9-96bc-f26292919067',\n",
       " '1a565664-3a93-4fcc-a3d7-f69ea902c362',\n",
       " '6fbb8111-bf9a-4aaf-a978-3e564facd5d7',\n",
       " 'dc261041-ecf0-45ee-82f0-db1c0f943ce9',\n",
       " 'a5469b86-7a88-464a-ad64-d3e9378245b9',\n",
       " 'ff60d5ee-9eca-4f5d-985a-031103f4cf19',\n",
       " 'b25e5965-8f6e-4280-b0fa-2eea70e1ced7',\n",
       " 'b503a47b-0edd-42fd-91dc-a0d170e60c5b',\n",
       " '3e245584-aa77-4021-9fdf-f421a0121135',\n",
       " '10bf245a-edac-42f7-9d60-deaf29091798',\n",
       " 'dbd361d6-03a7-4313-9a00-e978173623cf',\n",
       " '1e277ee8-0c83-49f5-a41a-05880e42a912',\n",
       " 'edfbd25d-de40-4573-bca0-ebda4b068bf2',\n",
       " '5f608808-781d-4611-a194-395edd448855',\n",
       " '5316ce82-7a1f-4444-a175-91b69b2679e5',\n",
       " '35331ac3-8a2a-422a-bf0f-fc94047cb295',\n",
       " 'a03598ed-2405-40e7-97b3-b26e6a116eac',\n",
       " '61e8efca-650b-4a7f-a273-4e00a38b999b',\n",
       " '116650c6-9471-4366-a9be-3e30ca37a656',\n",
       " '0719813b-6d36-4c19-b231-13fb65d95536',\n",
       " 'f64fbf19-5f4e-495c-ab7b-5b9fea2e86f1',\n",
       " '793188d8-b350-4174-a171-6c271c73bb2d',\n",
       " 'f85d6025-ec2b-43ea-a446-de230b6321a1',\n",
       " '31555ebb-85b9-4828-9e2d-759cf2002c51',\n",
       " 'e69201ad-2fb2-43ce-b866-3521aed85a8a',\n",
       " 'fb88f4db-5aac-4673-a98b-5844d1844166',\n",
       " '82b9ef9b-c104-408b-bb11-0f4bcab9041f',\n",
       " 'c0f202b8-e4f2-47fe-bc32-1d32307df605',\n",
       " '5d17e002-38bc-4808-a61c-37920c99dc17',\n",
       " 'f0add662-3eeb-41a7-b591-62b6d12518f7',\n",
       " '82ffa43a-202a-4438-be22-e71068780683',\n",
       " 'b640c5bf-eb40-4619-948f-dca3ddeb50e7',\n",
       " '3ae9d20b-81fd-4d29-9c4e-4f1f378fa22f',\n",
       " 'ad2fd590-7e11-47f3-8322-4f43161939cc',\n",
       " 'a3d7a05b-e664-47cf-9a40-9d6004aa6435',\n",
       " '63f26dd4-f01a-4ab6-99a7-960c072b4213',\n",
       " '107e49bc-5624-4170-960d-14b1fdf51e9a',\n",
       " '9c5ad5db-6223-4845-a457-f2b469ea2897',\n",
       " '74e5ce27-1827-4a4b-8bab-7f2a2e697b70',\n",
       " '1b72fd94-40d3-4fe0-93e9-11ea74ccc89d',\n",
       " 'a54ed7ea-4d01-4df0-8987-3ef43236ff82',\n",
       " 'b9accefc-d8b6-4366-a352-375fea8f1768',\n",
       " 'fe323a72-5e9e-4152-b0df-a16e057e630e',\n",
       " '9033ca2a-c457-453c-9c4f-3d40bc5bfc5f',\n",
       " 'd26e8a49-65d3-4a22-9b6e-a1a302669161',\n",
       " '338fde24-184c-45b8-ba00-4bacc15ef399',\n",
       " 'cdad1b5a-0e60-41b8-800f-42e0eeb51537',\n",
       " '7d9c427e-7790-4c64-9c66-44528795fa57',\n",
       " '5d94ac43-19db-491c-81b8-2f8394c15e82',\n",
       " '26528f7d-f205-4cd3-9f95-3e1ade3969dd',\n",
       " 'e900ccf7-4f85-4707-9c21-200ceb1ad273',\n",
       " '74102064-951b-4dec-953d-b7fe28e6d084',\n",
       " 'be08eaba-0b08-458c-8d40-b7e9d51e866e',\n",
       " 'e75d656f-4ab1-4b34-8220-dfb40f0f2a69',\n",
       " '1ad003bd-2263-4489-bc7c-3a501e710982',\n",
       " '0d7481b0-7eb3-4559-8f88-7979a34a17f2',\n",
       " '2b05aaf5-3658-42bd-8195-5ce4c354a001',\n",
       " '0ad7b183-ce8d-4f4a-aa07-fc63a28827ff',\n",
       " '4b216494-26bc-4b57-b867-613bb34cf255',\n",
       " '91a30ebe-d26d-4643-8b25-0dd5ef0b1474',\n",
       " 'c4a29c1b-6e1f-42bd-8a1c-60a961330afd',\n",
       " '74aeef1c-41b6-4511-8d0f-ad4b1b86ff46',\n",
       " '9ccff6c6-d96a-4f28-8df1-fbf05df6e68c']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vsm.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81fa5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vsm.save_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edf5bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vsm.load_local(allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5d957",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d8afcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.08s, count=6\n",
      "[METRICS] similarity_search_with_score: time=0.09s, count=2\n"
     ]
    }
   ],
   "source": [
    "retrieved = vsm.similarity_search_with_score(query=\"experience at dolf\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfaf2249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Created retriever for 'index' with {'search_type': 'similarity', 'search_kwargs': {'k': 2}}\n"
     ]
    }
   ],
   "source": [
    "retriever = vsm.retriever(search_type = \"similarity\", search_kwargs = {\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4088866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.17s, count=8\n"
     ]
    }
   ],
   "source": [
    "retrieved = retriever.invoke(\"projects by snakalp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc659565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- time recommendations, graph - based search or supply - chain management, be sure to review all the different ways in which graph technology can work for your company. and while our customers span several continents and professional fields, they all agree that using the neo4j graph database is a critical component of their business success and competitiveness. are you a developer eager to learn more about making the switch? with so many ways to quickly get started, mastering graph database development is one of the best time investments you can make. other resources videos : • intro to neo4j and graph databases • intro to graph databases episode # 1 - evolution of dbs books : • o ’ reilly book : graph databases • learning neo4j trainings : • online training : getting started with neo4j • classroom trainings whether you need a solution that provides real - time recommendations, graph - based search or supply - chain management, be sure to review all the different ways in which graph technology can work for your company.',\n",
       " 'data, especially if they ’ re tackling a graph - based problem. if your team comes from an sql background, a query language like cypher will be easy to learn and even easier to execute. and when it comes to your enterprise - level application, you ’ ll be glad that the language underpinning it all is build for speed and efficiency. if your team comes from an sql background, a query language like cypher will be easy to learn and even easier to execute. and when it comes to your enterprise - level application, you ’ ll be glad that the language underpinning it all is build for speed and efficiency.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [ret.page_content for ret in retrieved]\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fedc8e",
   "metadata": {},
   "source": [
    "### Supported LLMs (as of 06/05/2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebcd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_llms=[\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f9368be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from config.settings import settings\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=settings.HF_TOKEN.get_secret_value(),\n",
    ")\n",
    "\n",
    "def get_answer(\n",
    "    sys_prompt: str,\n",
    "    query: str,\n",
    "    model: str = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Send a system + user prompt to the specified model via HF Inference,\n",
    "    returning the assistant’s content string.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\",   \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01a5776d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A concise question about Westeros! Here are the **Top Houses in Game of Thrones**, in no particular order, highlighting their **Sigil**, **Motto**, and **Notable Members**:\\n\\n1. **House Stark**\\n\\t* **Sigil**: Direwolf\\n\\t* **Motto**: \"Winter is Coming\"\\n\\t* **Notable Members**: Eddard (Ned), Robb, Sansa, Arya, Bran, Jon Snow\\n\\n2. **House Lannister**\\n\\t* **Sigil**: Lion\\n\\t* **Motto**: \"Hear Me Roar!\"\\n\\t* **Notable Members**: Cersei, Jaime, Tyrion, Tywin, Kevan\\n\\n3. **House Targaryen**\\n\\t* **Sigil**: Dragon\\n\\t* **Motto**: \"Fire and Blood\"\\n\\t* **Notable Members**: Daenerys, Viserys, Rhaegar, Aerys II (Mad King), Jon Snow (Aegon Targaryen)\\n\\n4. **House Baratheon**\\n\\t* **Sigil**: Stag\\n\\t* **Motto**: \"Ours is the Fury\"\\n\\t* **Notable Members**: Robert, Stannis, Renly, Joffrey, Myrcella, Tommen\\n\\n5. **House Tyrell**\\n\\t* **Sigil**: Rose\\n\\t* **Motto**: \"Growing Strong\"\\n\\t* **Notable Members**: Mace, Loras, Margaery, Olenna (Queen of Thorns)\\n\\n6. **House Greyjoy**\\n\\t* **Sigil**: Kraken\\n\\t* **Motto**: \"We Do Not Sow\"\\n\\t* **Notable Members**: Balon, Yara, Theon, Euron\\n\\n7. **House Arryn**\\n\\t* **Sigil**: Falcon\\n\\t* **Motto**: \"As High as Honor\"\\n\\t* **Notable Members**: Jon Arryn, Lysa, Robin, Yohn Royce (conditional ally)\\n\\n8. **House Martell**\\n\\t* **Sigil**: Spear\\n\\t* **Motto**: \"Unbowed, Unbent, Unbroken\"\\n\\t* **Notable Members**: Oberyn, Ellaria, Doran, Trystane, Arianne\\n\\nThese houses are central to the plot and power struggles throughout the series. Of course, there are many other influential houses in the world of Game of Thrones, but these are generally considered the most pivotal.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(sys_prompt=\"you are a helpful assistant who answers the users query concisely\", query=\"what are the top houses in game of thrones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e802c",
   "metadata": {},
   "source": [
    "### Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce481ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.HuggingFaceLLM import HuggingFaceLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd369d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_llm = HuggingFaceLLM(model_name=\"meta-llama/Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9663d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg_llm.get_answer(sys_prompt=\"you are a helpful assistant that answers concisely\", user_prompt=\"what is quantum computing ?\", max_tokens = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3192ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.PromptAugmentor import PromptAugmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78dd5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = PromptAugmentor(client=pg_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3aad6d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.generation.PromptAugmentor:Requesting synthetic prompt 1/2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 136 characters\n",
      "INFO:src.generation.PromptAugmentor:Generated prompt #1: 'What is the key difference between a Graph Database and a traditional Vector Database in terms of data structure and query capabilities?'\n",
      "INFO:src.generation.PromptAugmentor:Requesting synthetic prompt 2/2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 102 characters\n",
      "INFO:src.generation.PromptAugmentor:Generated prompt #2: 'What are the primary use cases for Graph Databases versus Vector Databases in real-world applications?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is the key difference between a Graph Database and a traditional Vector Database in terms of data structure and query capabilities?',\n",
       " 'What are the primary use cases for Graph Databases versus Vector Databases in real-world applications?',\n",
       " 'what is a graph db and how is it different from a regular VectorDB ?']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = augmentor.generate(query=\"what is a graph db and how is it different from a regular VectorDB ?\", synthetic_count=2)\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "619c97da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ingestion.VectorStoreManager:Created retriever for 'index' with {'search_type': 'similarity', 'search_kwargs': {'k': 4}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS] embed_query: time=0.14s, count=25\n",
      "[METRICS] embed_query: time=0.23s, count=20\n",
      "[METRICS] embed_query: time=0.28s, count=18\n"
     ]
    }
   ],
   "source": [
    "retriever = vsm.retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "prompt_chunks = [(p, retriever.invoke(p)) for p in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43d93531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.Fusion import FusionSummarizer\n",
    "from src.generation.Prompts import Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9161b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_summarizer = FusionSummarizer(fusion_llm=pg_llm,sys_prompt=Prompts.MERGE_FUSION_SYS_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72f3d459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.generation.Fusion:Generating summary for prompt 1: 'What is the key difference between a Graph Databas...'\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 1111 characters\n",
      "INFO:src.generation.Fusion:Generating summary for prompt 2: 'What are the primary use cases for Graph Databases...'\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 1111 characters\n",
      "INFO:src.generation.Fusion:Generating summary for prompt 3: 'what is a graph db and how is it different from a ...'\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.1-8B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 1301 characters\n"
     ]
    }
   ],
   "source": [
    "summaries = fusion_summarizer.summarize(prompt_chunks=prompt_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9858267",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summaries = \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "132c3d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.generation.HuggingFaceLLM:Creating new HuggingFaceLLM for model: meta-llama/Llama-3.3-70B-Instruct\n",
      "INFO:src.generation.HuggingFaceLLM:InferenceClient initialized for model: meta-llama/Llama-3.3-70B-Instruct\n"
     ]
    }
   ],
   "source": [
    "final_llm = HuggingFaceLLM(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "607a3b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.generation.HuggingFaceLLM:get_answer called\n",
      "INFO:src.generation.HuggingFaceLLM:API call successful: model=meta-llama/Llama-3.3-70B-Instruct messages=2\n",
      "INFO:src.generation.HuggingFaceLLM:get_answer returning 599 characters\n"
     ]
    }
   ],
   "source": [
    "final_answer = final_llm.get_answer(sys_prompt=Prompts.FINAL_ANS_SYS_PROMPT,user_prompt=\"User Question: \\nwhat is a graph db and how is it different from a regular VectorDB ? \\n\\n Context: \\n\"+all_summaries,max_tokens = 400, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9fdbccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A graph database is an online, operational database management system that operates on a graph data model, storing data as nodes and relationships. It is different from a regular VectorDB in terms of data model, storage, and processing. Graph databases use a graph data model, native graph storage, and native graph processing, whereas VectorDBs are suited for dense, high-dimensional data and are often used in scenarios such as recommendation systems, image and speech recognition, and Natural Language Processing (NLP). Insufficient information is available to provide a more detailed comparison.\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
