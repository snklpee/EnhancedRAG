{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7062c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Cargo is Rust’s build system and package manager. Most Rustaceans use this tool to manage their Rust projects because Cargo handles a lot of tasks for you, such as building your code, downloading the libraries your code depends on, and building those libraries. (We call the libraries that your code needs dependencies.)\\n\\nThe simplest Rust programs, like the one we’ve written so far, don’t have any dependencies. If we had built the “Hello, world!” project with Cargo, it would only use the part of Cargo that handles building your code. As you write more complex Rust programs, you’ll add dependencies, and if you start a project using Cargo, adding dependencies will be much easier to do.\\n\\nBecause the vast majority of Rust projects use Cargo, the rest of this book assumes that you’re using Cargo too. Cargo comes installed with Rust if you used the official installers discussed in the “Installation” section. If you installed Rust through some other means, check whether Cargo is installed by entering the following in your terminal:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def835c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0ba805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42830527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "\n",
    "splitter = SentenceTransformersTokenTextSplitter.from_huggingface_tokenizer(tokenizer=hf_tokenizer,chunk_overlap=50, tokens_per_chunk=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "862900f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "tokens = splitter.count_tokens(text=\"whats up ?\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0d3df62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "chunks = splitter.split_text(text)\n",
    "print(len(chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_chunker (txt, hf_tokenizer, chunk_size: int, chunk_overlap: int):\n",
    "    \"\"\"makes chunks from text\"\"\"\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        tokenizer = AutoTokenizer.from_pretrained(hf_tokenizer),\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = chunk_overlap\n",
    "    )\n",
    "    \n",
    "    chunks = splitter.split_text(txt)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "def embed_query(text: str):\n",
    "    \n",
    "    embedded_query = embedding_model.embed_query(text)\n",
    "    dimension = len(embedded_query)\n",
    "    \n",
    "    return embedded_query, dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6bcc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_query, dimension = embed_query(\"what is it really like ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcb57293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9ec43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "def embed_query(text: str):\n",
    "    \n",
    "    embedded_query = embedding_model.embed_query(text)\n",
    "    dimension = len(embedded_query)\n",
    "    \n",
    "    return embedded_query, dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embedding_model.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embedding_model,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    "    distance_strategy=DistanceStrategy.COSINE\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a7e277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0d95502d-a690-48ca-82ba-5b6bccff731d',\n",
       " '5ddf91a9-73dc-406d-a778-a5ba4fefa9d3',\n",
       " '2caf6b35-765b-42f0-b9f6-4d4b0ec99971']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc192a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x77d2a1e14f80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.save_local(folder_path=\"vector_stores\")\n",
    "# vector_store.load_local(folder_path=\"vector_stores\", embeddings=embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb604e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}] page_content='Building an exciting new project with LangChain - come check it out!' metadata={'source': 'tweet'}\n",
      "* I had chocalate chip pancakes and scrambled eggs for breakfast this morning. [{'source': 'tweet'}] page_content='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.' metadata={'source': 'tweet'}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}] {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5e19e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2caf6b35-765b-42f0-b9f6-4d4b0ec99971\n"
     ]
    }
   ],
   "source": [
    "print(results[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index():\n",
    "    def "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
